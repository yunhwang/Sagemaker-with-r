{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker와 R을 이용하여 하이퍼파라미터 튜닝 및 자체 제작 R 알고리즘 컨테이너 사용하기\n",
    "_**Using Amazon SageMaker's Hyperparameter Tuning with a customer Docker container and R algorithm**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 목차\n",
    "\n",
    "1. [배경](#배경)\n",
    "2. [설정](#설정)\n",
    "  1. [권한](#권한)\n",
    "3. [코드](#코드)\n",
    "  1. [퍼블리시](#퍼블리시)\n",
    "4. [데이터](#데이터)\n",
    "5. [튜닝](#튜닝)\n",
    "6. [HPO 분석](#HPO-분석)\n",
    "7. [호스팅](#호스팅)\n",
    "8. [예측](#예측)\n",
    "9. [(Optional) 리소스 삭제](#(Optional)-리소스-삭제)\n",
    "10. [정리](#정리)\n",
    "\n",
    "---\n",
    "## 배경\n",
    "\n",
    "R은 데이터 사이언스와 머신 러닝에서 오랫동안 사용해 온 오픈 소스 통계 프로그래밍 언어입니다. 여러 사용자들과 커뮤니티에서 R 패키지를 통해 사용할 수 있는 다양한 알고리즘들을 활용하고 있습니다. 이 예제에서는 그중 한 알고리즘인 ([Multivariate Adaptive Regression Splines](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines))을 SageMaker의 하이퍼파라미터 튜닝 기능과 함께 사용하여 모델을 만들어 볼 예정입니다. 이 작업에는 잘 알려진 [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)을 사용하겠습니다.\n",
    "\n",
    "이 노트북에서는 고객이 직접 제작한 알고리즘 컨테이너(BYOC)와 하이퍼파라미터 튜닝을 함께 사용하는 방법을 보여드리는 데에 초점을 맞출 예정입니다. 또한 튜닝된 모델을 엔드포인트로 만들어 호스팅하고 추론 작업을 할 수 있게 하는 방법도 설명할 예정입니다. 더 많은 예를 보시고자 하는 경우, 이 [notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/r_bring_your_own/r_bring_your_own.ipynb)을 참조해 주세요.\n",
    "\n",
    "\n",
    "---\n",
    "## 설정\n",
    "\n",
    "_이 노트북은 ml.m4.xlarge 노트북 인스턴스로 작성 및 테스트하였습니다_\n",
    "\n",
    "본격적으로 시작하기 앞서, 필수적인 내용들을 정의해 줍니다:\n",
    "\n",
    "- 데이터와 모델 아티팩트를 저장할 S3 버킷\n",
    "- 데이터 트레이닝과 모델 생성 시 사용할 접두사. 참고로 S3 버킷과 노트북 인스턴스, 트레이닝 및 추론에 사용되는 자원들은 같은 리전에 있어야 합니다.\n",
    "- 트레이닝과 추론 시 데이터에 접근할 수 있는 권한을 가진 IAM 역할이 필요합니다. 이 IAM 역할을 만드는 방법은 이 [문서](https://docs.aws.amazon.com/sagemaker/latest/dg/using-identity-based-policies.html)를 참조해 주세요. 만약 지금 사용하고 있는 노트북 인스턴스에 이 역할이 연결되어 있지 않거나 트레이닝 또는 추론 호스팅에 하나 이상의 역할이 필요한 경우, 아래 노트북의 `sagemaker.get_execution_role()` 부분을 적합한 IAM 역할의 ARN으로 변경해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "# Turn warnings off globally\n",
    "options(warn=-1)\n",
    "\n",
    "# Install reticulate library and import sagemaker\n",
    "library(reticulate)\n",
    "sagemaker <- import('sagemaker')\n",
    "\n",
    "bucket <- session$default_bucket()\n",
    "prefix <- 'sagemaker/DEMO-hpo-r-byo'\n",
    "\n",
    "role_arn <- sagemaker$get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 노트북에서 실행할 라이브러리들을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBC\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 권한\n",
    "\n",
    "이 노트북을 실행하기 위해서는 일반적인 `SageMakerFullAccess` 정책보다 더 많은 권한을 필요로 합니다. Amazon ECR에 새로운 저장소를 생성해야 하기 때문이죠. 이 권한을 추가하는 가장 쉬운 방법은 현재 노트북 인스턴스에 연결되어 있는 역할에 관리형 정책인 `AmazonEC2ContainerRegistryFullAccess`를 추가해 주는 것입니다. 일단 추가하고 나면 노트북을 재시작할 필요 없이 해당 권한은 바로 적용됩니다. \n",
    "sions will be available immediately.\n",
    "\n",
    "---\n",
    "## 코드\n",
    "\n",
    "이 예제를 위해 3개의 추가적인 코드 파일들을 사용합니다. 여기서는 일단 각 파일들이 어떤 역할을 하는지 간단히 설명하겠습니다. 자세한 내용은 직접 노트북으로 파일을 열어 확인해 보세요.\n",
    "\n",
    "- **Fit**: `mars.R`을 이용하여 모델을 트레이닝하고 추론용 모델을 제공합니다.\n",
    "- **Serve**: `plumber.R`은 [plumber](https://www.rplumber.io/)패키지를 이용하여 가벼운 HTTP 서버를 호스팅하고 요청을 처리합니다. 특정 문법을 사용하는 점을 확인해 주시고, 구체적인 사용 사례들에 대한 세부 사항은 plumber 도움말 문서를 참조해 주세요.\n",
    "- **Dockerfile**: 이 파일을 토대로 이후 도커 컨테이너를 만들게 됩니다. 컨테이너의 사이즈가 작을수록 SageMaker를 통해 트레이닝을 하거나 엔드포인트를 생성할 때 컨테이너를 빠르게 띄울 수 있기 때문에, 꼭 필요한 것만 구성하도록 했습니다. 여기서는 먼저 Ubuntu를 베이스 이미지로 가져와서 R, mda, 그리고 plumber 라이브러리를 설치하고, `mars.R` 과 `plumber.R`을 추가한 다음, 마지막으로 컨테이너가 호출될 때 `mars.R`이 실행되도록 엔트리포인트(entrypoint)를 설정했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 퍼블리시\n",
    "이제 이 컨테이너를 ECR에 업로드하기 위해 아래 명령어를 실행합니다.\n",
    "\n",
    "처음 실행하는 경우 완료되는 데까지 다소 시간이 소요될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_name = 'rmars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=rmars\n",
    "\n",
    "#set -e # stop if anything fails\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 데이터\n",
    "이 예제에서 우리는 `iris` 데이터셋을 사용합니다. 이 데이터셋은 작지만 지도 학습 알고리즘을 테스트하는 데에 많이 사용되어 온 고전적인 자료입니다. 보통 목표는 꽃의 다양한 속성들을 토대로 세 가지 종류의 꽃 중 하나로 예측하는 것이 일반적입니다. 자세한 내용은 [여기](https://en.wikipedia.org/wiki/Iris_flower_data_set)를 참조해 주세요.\n",
    "\n",
    "트레이닝용 데이터와 테스트 데이터를 70% / 30% 로 나누고, 나누어진 데이터 파일들을 S3에 복사하여 SageMaker 트레이닝에서 접근할 수 있도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split, 70%-30%\n",
    "train_data = data.sample(frac=0.7, random_state=42)\n",
    "test_data = data.drop(train_data.index)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "train_data.to_csv('iris_train.csv', index=False)\n",
    "test_data.to_csv('iris_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to S3\n",
    "train_file = 'iris_train.csv'\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', train_file)).upload_file(train_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_참고: 노트북에서 예비 데이터 변환을 할 수 있지만 그렇게 하지 않고, 컨테이너 내부에서 변환을 수행하도록 할 예정입니다. 모델의 효율성을 위해서는 권고하는 방법은 아닙니다만, 대신 유연성 면에서 장점이 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 튜닝\n",
    "\n",
    "이제 `iris` 데이터로 Multivariate Adaptive Regression Splines 모델을 트레이닝하기 위해 필요한 내용들을 정리해 보겠습니다. 이 예제에서 우리는 전형적인 분류 예측인 `Species`가 아니라, `Sepal.Length`를 예측해 볼 생각입니다. 이를 통해 회귀 분석을 사용하고, 어떤 요소들이 모델에 포함될 수 있는지 확인해 볼 겁니다.\n",
    "\n",
    "먼저, 리전과 계정 정보를 가져와 위에서 생성한 ECR 컨테이너를 불러올 준비를 하곘습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "account = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 estimator를 생성할 겁니다. 여기서는 아래와 같은 내용들을 설정해 주어야 합니다:\n",
    "- ECR에 저장되어 있는 트레이닝용 컨테이너 이미지\n",
    "- SageMaker의 함수들을 실행하고 S3에 저장된 데이터에 접근할 수 있는 IAM 역할\n",
    "- 트레이닝 인스턴스의 타입과 개수\n",
    "- 모델 아티팩트를 저장할 S3 경로\n",
    "- 튜닝 시 모든 트레이닝 작업에서 공유하여 사용할 하이퍼파라미터(튜닝되지 않고 상수형으로 사용됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_name='{}.dkr.ecr.{}.amazonaws.com/rmars:latest'.format(account, region),\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    hyperparameters={'degree': 2})      # Setting constant hyperparameter\n",
    "\n",
    "# target is by defauld \"Sepal.Length\". See mars.R where this is set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator를 정의하고 나면 튜닝하고자 하는 하이퍼파라미터를 지정할 수 있습니다. 여기서 하이퍼파라미터는 3가지 타입이 있습니다.\n",
    "- 카테고리형(Categorical) 파라미터: 이산적인 값들 중 하나를 택해야 하는 경우. 이 타입의 하이퍼파라미터를 정의하기 위해서는 가능한 값들을 리스트로 만들어 `CategoricalParameter(list)`와 같은 형태로 지정합니다.\n",
    "- 지속형(Continous) 파라미터: 최소값과 최대값 사이의 모든 실수(real number)를 고를 수 있는 경우. `ContinuousParameter(min, max)`로 지정할 수 있습니다.\n",
    "- 정수형(Integer) 파라미터: 최소값과 최대값 사이 정수를 고를 수 있는 경우. `IntegerParameter(min, max)`로 지정합니다.\n",
    "\n",
    "*참고: 가능하다면 가장 제약이 적은 형태로 값을 지정하는 것이 좋습니다. 예를 들어 `thresh`를 튜닝할 때, 지속형 파라미터로 0.01과 0.2 사이 값을 지정하는 것이 카테고리형 파라미터로 0.01, 0.1, 0.15, 0.2 중 선택하도록 하는 것보다 더 나은 결과를 얻을 수 있습니다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set the degree as a varying HP to tune, use: 'degree': IntegerParameter(1, 3) and remove it from the Estimator\n",
    "\n",
    "hyperparameter_ranges = {'thresh': ContinuousParameter(0.001, 0.01),\n",
    "                         'prune': CategoricalParameter(['TRUE', 'FALSE'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 튜닝할 대상 메트릭과 그 정의를 설정합니다. 여기서 지정하는 이 메트릭은 앞서 본 `mars.R` 파일에서 `print` 구문으로 출력됩니다. 이후 트레이닝 작업이 기록하는 Cloudwatch logs에서 이 메트릭 값을 가져올 것이기 때문에,  정규식(Regex) 포맷에 맞도록 설정하는 것이 매우 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'mse'\n",
    "metric_definitions = [{'Name': 'mse',\n",
    "                       'Regex': 'mse: ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `HyperparameterTuner` 오브젝트를 만들어 보겠습니다. 여기서는 다음 내용들을 정의해 주어야 합니다:\n",
    "- 위에서 생성한 estimator\n",
    "- 하이퍼파라미터의 튜닝 범위\n",
    "- 목표 메트릭 이름과 정의\n",
    "- 목표 메트릭을 최대값을 택해야 하는지 최소값을 택해야 하는지 여부 ('Maximize'가 기본값)\n",
    "- 총 몇 개의 트레이닝 작업을 수행해야 하는지와 한 번에 몇 개의 트레이닝 작업을 수행할 것인지. 동시에 많은 트레이닝 작업을 수행할수록 튜닝은 빨리 끝나지만, 정확도가 떨어질 수 있습니다. 일반적으로 전체 트레이닝 작업 수의 10% 미만을 한 번에 수행할 트레이닝 작업의 수로 설정하기를 추천합니다. (여기서는 트레이닝을 빨리 끝내기 위해 비율을 높게 조정했습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            objective_type='Minimize',\n",
    "                            max_jobs=9,\n",
    "                            max_parallel_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 `.fit()`을 호출하여 하이퍼파라미터 튜닝 작업을 시작합니다. 이 때 트레이닝 및 테스트용 데이터셋이 저장되어 있는 S3 경로를 지정합니다.\n",
    "\n",
    "*참고: 일반적으로 하이퍼파라미터 튜닝을 하는 경우, 트레이닝용과 검증용(또는 테스트용) 데이터셋을 지정하고 검증용 데이터셋을 통해 목표 메트릭을 최적화하는 것을 추천합니다. 그러나 `iris`는 매우 작은 데이터셋이어서 여기서는 트레이닝과 검증용 데이터를 나누는 부분을 스킵하겠습니다. 실전에서 이렇게 하는 경우 트레이닝 데이터에 오버피팅 된, 일반화가 어려운 모델을 얻게 될 수 있습니다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': 's3://{}/{}/train'.format(bucket, prefix)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단히 하이퍼파라미터 튜닝 작업 상태를 확인해 보겠습니다. 잘 실행되었는지, 현재 `InProgress` 상태인지 아래와 같이 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "status = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n",
    "\n",
    "while status != \"Completed\":\n",
    "    status = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n",
    "    \n",
    "    completed = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['TrainingJobStatusCounters']['Completed']\n",
    "    \n",
    "    prog = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['TrainingJobStatusCounters']['InProgress']\n",
    "    \n",
    "    print(f'{status}, Completed Jobs: {completed}, In Progress Jobs: {prog}')\n",
    "    \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터 최적화 작업이 끝나면 아래 셀을 실행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['BestTrainingJob']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## HPO 분석\n",
    "\n",
    "하이퍼파라미터 튜닝 작업은 백그라운드에서 진행되기 때문에 이 노트북을 닫아도 됩니다. 작업이 완료되면, [HPO Analysis notebook](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb)를 이용하여 어떤 하이퍼파라미터들이 가장 적합했는지 결정할 수 있습니다.\n",
    "\n",
    "SageMaker의 하이퍼파라미터 튜닝에 대한 세부 사항은 AWS Documentation을 확인해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 호스팅\n",
    "\n",
    "튜닝한 모델을 Amazon SageMaker에서 호스팅하는데에는 세 단계면 충분합니다. 먼저, 호스팅하고자 하는 모델을 정의합니다. 아까 트레이닝 작업에서 S3에 저장한 모델 아티팩트를 지정하면 됩니다.\n",
    "`hyper_parameter_tuning_job` 메소드를 사용하여 HPO 결과물을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training = boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['BestTrainingJob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best trainig job and S3 location for the model file\n",
    "best_model_s3 = boto3.client('sagemaker').describe_training_job(\n",
    "    TrainingJobName=best_training['TrainingJobName'])['ModelArtifacts']['S3ModelArtifacts']\n",
    "best_model_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "r_job = 'DEMO-r-byo-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_hosting_container = {\n",
    "    'Image': '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name),\n",
    "    'ModelDataUrl': best_model_s3\n",
    "}\n",
    "\n",
    "create_model_response = boto3.client('sagemaker').create_model(\n",
    "    ModelName=r_job,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer=r_hosting_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 엔드포인트 설정을 만듭니다. 우리가 방금 등록한 모델을 인수로 지정합니다. 여기서는 t2.medium 한 개를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_endpoint_config = 'DEMO-r-byo-config-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(r_endpoint_config)\n",
    "\n",
    "create_endpoint_config_response = boto3.client('sagemaker').create_endpoint_config(\n",
    "    EndpointConfigName=r_endpoint_config,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.t2.medium',\n",
    "        'InitialInstanceCount': 1,\n",
    "        'ModelName': r_job,\n",
    "        'VariantName': 'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 위의 설정을 토대로 엔드포인트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "r_endpoint = 'DEMO-r-endpoint-' + time.strftime(\"%Y%m%d%H%M\", time.gmtime())\n",
    "print(r_endpoint)\n",
    "create_endpoint_response = boto3.client('sagemaker').create_endpoint(\n",
    "    EndpointName=r_endpoint,\n",
    "    EndpointConfigName=r_endpoint_config)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = boto3.client('sagemaker').describe_endpoint(EndpointName=r_endpoint)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "try:\n",
    "    boto3.client('sagemaker').get_waiter('endpoint_in_service').wait(EndpointName=r_endpoint)\n",
    "finally:\n",
    "    resp = boto3.client('sagemaker').describe_endpoint(EndpointName=r_endpoint)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Arn: \" + resp['EndpointArn'])\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "    if status != 'InService':\n",
    "        raise Exception('Endpoint creation did not succeed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 예측\n",
    "생성한 엔드포인트가 정상적으로 동작하는지 확인해 보겠습니다.\n",
    "\n",
    "_참고: 엔드포인트에 요청으로 보낼 페이로드는 헤더 레코드가 있는 CSV 문자열로,\n",
    "\n",
    "_Note: The payload we're passing in the request is a CSV string with a header record, followed by multiple new lines.  It also contains text columns, which the serving code converts to the set of indicator variables needed for our model predictions.  Again, this is not a best practice for highly optimized code, however, it showcases the flexibility of bringing your own algorithm._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "iris_test = pd.read_csv('iris_test.csv')\n",
    "\n",
    "runtime = boto3.Session().client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# there is a limit of max 500 samples at a time for invoking endpoints\n",
    "payload = iris_test.drop(['Sepal.Length'], axis=1).to_csv(index=False)\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=r_endpoint,\n",
    "                                   ContentType='text/csv',\n",
    "                                   Body=payload)\n",
    "\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the result is a CSV of predictions for our target variable.  Let's compare them to the actuals to see how our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.scatter(iris_test['Sepal.Length'], np.fromstring(result[0], sep=','), alpha=0.4, s=50)\n",
    "plt.xlabel('Sepal Length(Actual)')\n",
    "plt.ylabel('Sepal Length(Prediction)')\n",
    "x = np.linspace(*plt.xlim())\n",
    "plt.plot(x, x, linestyle='--', color='g', linewidth=1)\n",
    "plt.xlim(4,8)\n",
    "plt.ylim(4,8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean-up\n",
    "\n",
    "If you're ready to be done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').delete_endpoint(EndpointName=r_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
