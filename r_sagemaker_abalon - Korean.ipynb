{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Amazon SageMaker로 R 사용하기</h1>\n",
    "\n",
    "이 샘플 노트북은 [Amazon SageMaker](https://aws.amazon.com/sagemaker/) 및 [R](https://www.r-project.org/)을 사용하여 기계 학습 (ML) 모델에서 예측을 학습, 배포 및 검색하는 방법을 설명합니다. 여기서는 껍데기의 고리 수로 전복 연령을 예측해 봅니다. [reticulate](https://rstudio.github.io/reticulate/) 패키지는 [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/latest/index.html)의 R 인터페이스로, Amazon SageMaker에 대한 API 호출을 수행합니다. 또한 이 `reticulate` 패키지는 R과 Python object들을 변환해 주는 역할을 수행합니다. Amazon SageMaker는 대규모 ML 모델을 훈련하고 배포할 수 있는 서버리스 데이터 사이언스 환경을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>R에서 Amazon SageMaker Python SDK 호출 가능한 환경 만들기</h3>\n",
    "\n",
    "먼저, `reticulate` library를 로드하고 `sagemaker` 파이썬 모듈을 import 합니다. 모듈이 로드되고 나면 파이썬에서 `.` 으로 사용하던 클래스 notation을 R의 `$`로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고를 끕니다 - Turn warnings off globally\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 틱톡을 이용하여 코드 실행 시간을 측정합니다 - Install TicToc to measure code running time\n",
    "install.packages('tictoc', repos='http://cran.us.r-project.org')\n",
    "library(tictoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "sagemaker <- import('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>데이터 저장소를 생성하고 엑세스하기</h3>\n",
    "\n",
    "이 `Session` 클래스는 Amazon SageMaker에서 다음과 같은 [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) 리소스들을 사용할 수 있는 방법을 제공해 줍니다.\n",
    "\n",
    "* [S3](https://boto3.readthedocs.io/en/latest/reference/services/s3.html)\n",
    "* [SageMaker](https://boto3.readthedocs.io/en/latest/reference/services/sagemaker.html)\n",
    "* [SageMakerRuntime](https://boto3.readthedocs.io/en/latest/reference/services/sagemaker-runtime.html)\n",
    "\n",
    "데이터를 저장할 [Amazon Simple Storage Service](https://aws.amazon.com/s3/) 버킷을 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session <- sagemaker$Session()\n",
    "bucket <- session$default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고** - 이 `default_bucket` 함수는 아래와 같은 형식의 이름으로 새 Amazon S3 버킷을 생성합니다: \n",
    "\n",
    "`sagemaker-<aws-region-name>-<aws account number>`\n",
    "\n",
    "IAM role의 [ARN](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html) 을 지정하여 Amazon SageMaker가 Amazon S3 버킷에 접근할 수 있도록 해 줍니다. 이 노트북을 생성하는 데 사용된 IAM role을 이용할 수도 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn <- sagemaker$get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>데이터셋 다운로드하고 프로세싱하기</h3>\n",
    "\n",
    "이 모델은 [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)의 [abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone) 을 사용합니다. 먼저, 데이터를 다운로드하고 [exploratory data analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis)를 수행합니다. tidyverse packages를 이용하여 데이터를 읽고, 시각화하고, Amazon SageMaker로 다루기에 적합한 ML 포맷으로 데이터를 변환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(readr)\n",
    "data_file <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data'\n",
    "abalone <- read_csv(file = data_file, col_names = FALSE)\n",
    "names(abalone) <- c('sex', 'length', 'diameter', 'height', 'whole_weight', 'shucked_weight', 'viscera_weight', 'shell_weight', 'rings')\n",
    "head(abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 출력을 보면 factor 데이터 타입에 적합한 `sex`가 현재 character 데이터 타입으로 되어 있는 것을 확인할 수 있습니다. (F는 암컷, M은 수컷, 그리고 I는 새끼입니다) `sex`를 factor 데이터 타입으로 바꾸고 데이터셋의 통계를 살펴보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone$sex <- as.factor(abalone$sex)\n",
    "summary(abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 summary를 보면 `height`의 최소값이 0인 것을 볼 수 있습니다.\n",
    "\n",
    "각 `sex`의 값에 대해 `rings`와 `height` 간의 관계를 플로팅하여 어떤 전복의 키가 0인지 시각적으로 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "options(repr.plot.width = 5, repr.plot.height = 4) \n",
    "ggplot(abalone, aes(x = height, y = rings, color = sex)) + geom_point() + geom_jitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 [RBokeh](https://hafen.github.io/rbokeh/) 패키지를 사용해서 인터랙티브한 시각화를 해 볼 수도 있습니다. 패키지 문서 설명에 따르면, \n",
    "> \"*Bokeh는 웹 기반 플롯을 만들기 위한 유연하고 강력한 선언적 프레임 워크를 제공하는 시각화 라이브러리입니다. Bokeh는 HTML 캔버스를 사용하여 플롯을 렌더링하고 상호 작용할 수 있는 많은 메커니즘을 제공합니다. Bokeh는 현재 Python, Scala, Julia 및 R 인터페이스를 제공합니다.*\"\n",
    "\n",
    "`rbokeh` 는 SageMaker의 R kernel 커널에 표준으로 제공됩니다. 아래와 같이 이 라이브러리를 가져올 수 있습니다:\n",
    "\n",
    ">`library(rbokeh)`\n",
    "\n",
    "아래는 RBokeh를 사용하여 만든 인터랙티브 차트의 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import rbokeh\n",
    "library(rbokeh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p <- figure() %>%\n",
    "  ly_points(height, rings, data = abalone,\n",
    "    hover = list(height, rings))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 플롯에서 여러 개의 outlier들을 볼 수 있습니다. 두 새끼 전복들의 키가 0으로 표시되어 있고, 몇몇 암컷, 수컷 전복들이 다른 전복들보다 훨씬 큰 키로 표시되어 있네요. 키가 0으로 표기된 두 새끼 전복을 필터링해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "abalone <- abalone %>%\n",
    "  filter(height != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 트레이닝을 위해 데이터셋 준비하기</h3>\n",
    "\n",
    "이 모델을 위해서는 세 개의 데이터셋 - 트레이닝용, 테스팅용, 그리고 검증용 - 이 필요합니다. 먼저, `sex`를 [dummy variable](https://en.wikipedia.org/wiki/Dummy_variable_(statistics))로 변경하고 대상인 `rings`를 첫 번째 열로 바꿔줍니다. Amazon SageMaker 알고리즘은 대상이 데이터셋의 첫번째 열에 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone <- abalone %>%\n",
    "  mutate(female = as.integer(ifelse(sex == 'F', 1, 0)),\n",
    "         male = as.integer(ifelse(sex == 'M', 1, 0)),\n",
    "         infant = as.integer(ifelse(sex == 'I', 1, 0))) %>%\n",
    "  select(-sex)\n",
    "abalone <- abalone %>%\n",
    "  select(rings:infant, length:shell_weight)\n",
    "head(abalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 ML 알고리즘 학습을 위해 데이터의 70 %를 샘플링합니다. 나머지 30 %를 두 개로 나눠 테스트용과 검증용으로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_train <- abalone %>%\n",
    "  sample_frac(size = 0.7)\n",
    "abalone <- anti_join(abalone, abalone_train)\n",
    "abalone_test <- abalone %>%\n",
    "  sample_frac(size = 0.5)\n",
    "abalone_valid <- anti_join(abalone, abalone_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 트레이닝할 수 있도록 트레이닝 및 검증용 데이터를 Amazon S3에 업로드하겠습니다. 먼저 트레이닝 및 검증용 데이터셋을 .csv 형식으로 로컬 파일 시스템에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(abalone_train, 'abalone_train.csv', col_names = FALSE)\n",
    "write_csv(abalone_valid, 'abalone_valid.csv', col_names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음, 이 두 개의 데이터셋을 Amazon S3 버킷에 data라는 키 접두사를 붙여 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train <- session$upload_data(path = 'abalone_train.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')\n",
    "s3_valid <- session$upload_data(path = 'abalone_valid.csv', \n",
    "                                bucket = bucket, \n",
    "                                key_prefix = 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 Amazon SageMaker 알고리즘에 Amazon S3에서의 입력 형식을 정의해 줍니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_input <- sagemaker$s3_input(s3_data = s3_train,\n",
    "                                     content_type = 'csv')\n",
    "s3_valid_input <- sagemaker$s3_input(s3_data = s3_valid,\n",
    "                                     content_type = 'csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 트레이닝하기</h3>\n",
    "\n",
    "Amazon SageMaker 알고리즘들은 [Docker](https://www.docker.com/) 컨테이너 형태로 사용 가능합니다. [XGBoost](https://en.wikipedia.org/wiki/Xgboost) 모델을 트레이닝하기 위해, AWS 리전 내의 [Amazon Elastic Container Registry](https://aws.amazon.com/ecr/) (Amazon ECR)에 저장되어 있는 트레이닝 컨테이너를 지정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry <- sagemaker$amazon$amazon_estimator$registry(session$boto_region_name, algorithm='xgboost')\n",
    "container <- paste(registry, '/xgboost:latest', sep='')\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker [Estimator](http://sagemaker.readthedocs.io/en/latest/estimators.html)를 정의해 줍니다. 이 Estimator는 Docker로 컨테이너화 되어 있는 알고리즘을 트레이닝하는 데에 사용됩니다. 이 Estimator를 생성할 때에는 아래와 같은 인수들을 사용할 수 있습니다:\n",
    "* **image_name** - 트레이닝에 사용할 컨테이너 이미지 이름\n",
    "* **role** - Amazon SageMaker의 서비스 역할\n",
    "* **train_instance_count** - 트레이닝에 사용할 Amazon EC2 인스턴스들의 갯수\n",
    "* **train_instance_type** - 트레이닝에 사용할 Amazon EC2 인스턴스의 유형\n",
    "* **train_volume_size** - 트레이닝하는 동안 입력 데이터를 저장할 [Amazon Elastic Block Store](https://aws.amazon.com/ebs/) (Amazon EBS) 볼륨의 크기(GB)\n",
    "* **train_max_run** - 최대 트레이닝 시간 (타임아웃)\n",
    "* **input_mode** - 알고리즘이 지원하는 입력 방식\n",
    "* **output_path** - 트레이닝 결과(모델 artifact들과 출력 파일들)를 저장할 Amazon S3의 경로\n",
    "* **output_kms_key** - 트레이닝 결과를 암호화할 [AWS Key Management Service](https://aws.amazon.com/kms/) (AWS KMS)의 키\n",
    "* **base_job_name** - 트레이닝 작업에 접두사로 붙일 이름\n",
    "* **sagemaker_session** - Amazon SageMaker API과의 인터렉션을 관리할 세션 오브젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output <- paste0('s3://', bucket, '/output')\n",
    "estimator <- sagemaker$estimator$Estimator(image_name = container,\n",
    "                                           role = role_arn,\n",
    "                                           train_instance_count = 1L,\n",
    "                                           train_instance_type = 'ml.m5.large',\n",
    "                                           train_volume_size = 30L,\n",
    "                                           train_max_run = 3600L,\n",
    "                                           input_mode = 'File',\n",
    "                                           output_path = s3_output,\n",
    "                                           output_kms_key = NULL,\n",
    "                                           base_job_name = NULL,\n",
    "                                           sagemaker_session = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고** - R에서의 `NULL`의 경우 파이썬에서는 `None`으로 사용합니다.\n",
    "\n",
    "[XGBoost hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)를 지정하고 모델을 피팅해 봅니다. 트레이닝 라운드 수를 XGBoost 라이브러리의 통상 기본값인 100으로 설정합니다. 또한 현재 타임스탬프를 기반으로 입력 데이터와 작업 이름을 지정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic(\"Model Fitting\")\n",
    "estimator$set_hyperparameters(num_round = 100L)\n",
    "job_name <- paste('sagemaker-train-xgboost', format(Sys.time(), '%H-%M-%S'), sep = '-')\n",
    "input_data <- list('train' = s3_train_input,\n",
    "                   'validation' = s3_valid_input)\n",
    "estimator$fit(inputs = input_data,\n",
    "              job_name = job_name)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝이 끝나고 나면, Amazon SageMaker는 모델의 바이너리(gzip tarball)을 위에서 지정한 Amazon S3 출력 위치에 복사해 둡니다. Amazon S3의 전체 경로는 아래 명령어로 확인 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator$model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 배포하기</h3>\n",
    "\n",
    "Amazon SageMaker를 이용하면 쉽고 간단하게 모델을 배포하여([deploy your model](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)), 사용자들이 HTTPS request를 보낼 수 있는 API 엔드포인트를 제공할 수 있습니다. 우리가 방금 트레이닝시킨 모델을 `ml.t2.medium` 인스턴스에 배포해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic(\"Model Deployment\")\n",
    "model_endpoint <- estimator$deploy(initial_instance_count = 1L,\n",
    "                                   instance_type = 'ml.t2.medium')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델을 이용하여 예측 생성하기</h3>\n",
    "\n",
    "테스트 데이터를 사용하여 예측을 만들어 보겠습니다. 엔드포인트 설정에 `text/csv` 와 `csv_serializer`를 지정해서 콤마로 구분된(comma-separated) csv 텍스트를 JSON 포맷으로 직렬화하여 넘겨줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_endpoint$content_type <- 'text/csv'\n",
    "model_endpoint$serializer <- sagemaker$predictor$csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대상 열(column)을 지우고 처음 500개의 관찰(행)들을 열의 이름이 없는 매트릭스로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_test <- abalone_test[-1]\n",
    "num_predict_rows <- 500\n",
    "test_sample <- as.matrix(abalone_test[1:num_predict_rows, ])\n",
    "dimnames(test_sample)[[2]] <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고** - 관찰 행의 수를 500으로 설정한 이유는 엔드포인트의 제한을 넘기지 않기 위해서입니다.\n",
    "\n",
    "엔드포인트로부터 예측을 생성하고, 결과로 나온 콤마로 구분된(comma-separated) 문자열을 변환해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic(\"Invoke Endpoint\")\n",
    "library(stringr)\n",
    "predictions <- model_endpoint$predict(test_sample)\n",
    "predictions <- str_split(predictions, pattern = ',', simplify = TRUE)\n",
    "predictions <- as.numeric(predictions)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측한 고리의 수가 기록된 열을 테스트 데이터에 바인드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to Integer\n",
    "abalone_test <- cbind(predicted_rings = as.integer(predictions), \n",
    "                      abalone_test[1:num_predict_rows, ])\n",
    "head(abalone_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>엔드포인트 삭제하기</h3>\n",
    "\n",
    "모델을 모두 사용했다면, 엔드포인트를 삭제하여 비용이 낭비되지 않도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session$delete_endpoint(model_endpoint$endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
